{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82bf488-9023-458b-a0f1-ab299185ddc3",
   "metadata": {
    "id": "a82bf488-9023-458b-a0f1-ab299185ddc3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf98a7-b261-487a-9172-28dbcb9f7271",
   "metadata": {
    "id": "7caf98a7-b261-487a-9172-28dbcb9f7271"
   },
   "source": [
    "# Setting environment parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jMT11beJ9Brf",
   "metadata": {
    "id": "jMT11beJ9Brf"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain_openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "OVrJ4G8t9Jx8",
   "metadata": {
    "id": "OVrJ4G8t9Jx8"
   },
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "_7e5b3PF9dHg",
   "metadata": {
    "id": "_7e5b3PF9dHg"
   },
   "outputs": [],
   "source": [
    "# !pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c1a7756-c07a-4ac9-8b18-6f438af5ca3b",
   "metadata": {
    "id": "5c1a7756-c07a-4ac9-8b18-6f438af5ca3b"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "CHROMA_PATH = \".\\chroma6\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rIk55YUK9usm",
   "metadata": {
    "id": "rIk55YUK9usm"
   },
   "outputs": [],
   "source": [
    "# !pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a318f718-32fa-40f3-85a5-f84e54b58d4b",
   "metadata": {
    "id": "a318f718-32fa-40f3-85a5-f84e54b58d4b"
   },
   "source": [
    "# load data into Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95e8d2dd-46b2-427b-93f1-c2883a29ce55",
   "metadata": {
    "id": "95e8d2dd-46b2-427b-93f1-c2883a29ce55"
   },
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings()\n",
    "loaders = PyPDFLoader(\"/content/Panchatantra@RAG.pdf\")\n",
    "\n",
    "documents = loaders.load()\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    OpenAIEmbeddings(),\n",
    "    persist_directory=CHROMA_PATH\n",
    "  )\n",
    "db.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02bde2b6-b89a-4ecc-86e7-64770a5935eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "02bde2b6-b89a-4ecc-86e7-64770a5935eb",
    "outputId": "ad8af283-7d63-49bc-ba1a-c03319eb579a"
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.exit(1)7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "982711d9-4188-4efa-b580-41a80d620eea",
   "metadata": {
    "id": "982711d9-4188-4efa-b580-41a80d620eea"
   },
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    " - -\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d386f13-d08b-4a1e-b6c1-9b4d696fceeb",
   "metadata": {
    "id": "3d386f13-d08b-4a1e-b6c1-9b4d696fceeb"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c61dd0ef-48dd-41ef-91b3-a25c3bc31886",
   "metadata": {
    "id": "c61dd0ef-48dd-41ef-91b3-a25c3bc31886"
   },
   "outputs": [],
   "source": [
    "def query_rag(query_text):\n",
    "  \"\"\"\n",
    "  Query a Retrieval-Augmented Generation (RAG) system using Chroma database and OpenAI.\n",
    "  Args:\n",
    "    - query_text (str): The text to query the RAG system with.\n",
    "  Returns:\n",
    "    - formatted_response (str): Formatted response including the generated text and sources.\n",
    "    - response_text (str): The generated response text.\n",
    "  \"\"\"\n",
    "  # YOU MUST - Use same embedding function as before\n",
    "  embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "  # Prepare the database\n",
    "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "  # Retrieving the context from the DB using similarity search\n",
    "  results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "  # Check if there are any matching results or if the relevance score is too low\n",
    "  # if len(results) == 0 or results[0][1] < 0.7:\n",
    "  #   print(f\"Unable to find matching results.\")\n",
    "\n",
    "  # Combine context from matching documents\n",
    "  context_text = \"\\n\\n - -\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "\n",
    "  # Create prompt template using context and query text\n",
    "  prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "  prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "  # Initialize OpenAI chat model\n",
    "  model = ChatOpenAI()\n",
    "\n",
    "  # Generate response text based on the prompt\n",
    "  response_text = model.predict(prompt)\n",
    "\n",
    "   # Get sources of the matching documents\n",
    "  sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "\n",
    "  # Format and return response including generated text and sources\n",
    "  formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "  return formatted_response, response_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36979142-7e21-4ece-9af5-294ce37dc39a",
   "metadata": {
    "id": "36979142-7e21-4ece-9af5-294ce37dc39a"
   },
   "source": [
    "# Ask Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdf36209-00b1-4b11-a6db-64d25346e252",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdf36209-00b1-4b11-a6db-64d25346e252",
    "outputId": "21410118-7f9a-490d-cff0-e99fb961d884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The story of the monkey and the log\n",
      "2. The story of the jackal and the drum\n",
      "3. The story of the merchant Dantila\n",
      "4. The story of the jackal and the Sanyasi\n",
      "5. The story of the cobra and the crow\n"
     ]
    }
   ],
   "source": [
    "query_text=\"what are first 5 contents from PDF?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb7cf06a-57fb-4923-a4d8-d805c0e1585c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb7cf06a-57fb-4923-a4d8-d805c0e1585c",
    "outputId": "085121a0-50ee-4a2d-b98a-b01241b9ebd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The moral of the story is not to trust everyone blindly, as people with ill intentions may take advantage of your trust and deceive you. It also teaches the importance of being vigilant and not being swayed by honeyed words or flattery.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"THE STORY OF THE JACKAL AND THE SANYASI what is the moral from this?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "863b1eec-3e98-4099-916f-90ef9e2f96cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "863b1eec-3e98-4099-916f-90ef9e2f96cd",
    "outputId": "83f6449e-353c-4677-9ec7-873f04a06bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, it is not mentioned what is placed on page 28.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"whats placed in pgno 28\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "567dfbeb-df36-417b-9a8b-bc3e469d84ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "567dfbeb-df36-417b-9a8b-bc3e469d84ed",
    "outputId": "01ecaf6d-f5d9-45c4-9c35-a1a6243ff4b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The characters are a pair of crows (husband and wife), a black cobra, and a jackal.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"FHE STORY OF THl!. COBRA AND THE CROW what are the characters placed there?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68276242-ba5f-4f41-8534-34e2d93ebc83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68276242-ba5f-4f41-8534-34e2d93ebc83",
    "outputId": "d4cc9f8f-4814-4d64-8ba0-c84ed41725eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book provided in the context is translated by the author's \"t•ru\", Professor (Dr.) S.B. Hudlikar.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"the book which i have provided is translated by? \"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b13d139c-7039-484a-a257-64af45119f76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b13d139c-7039-484a-a257-64af45119f76",
    "outputId": "a4243c89-d6dc-4bdb-d1ad-5dc19ff567d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book was published by Rupa Publications India Pvt. Ltd.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"Provided book published by?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf3e6f-cae3-4d81-b614-6256b6ae3a5e",
   "metadata": {
    "id": "3cbf3e6f-cae3-4d81-b614-6256b6ae3a5e"
   },
   "source": [
    "# 1. get the embeddings for the query\n",
    "# 2. get the context from the chroma related to embeddings\n",
    "# 3. formulate the context based on query\n",
    "# 4. Ask the llm with the  context and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9294f7a-2c40-42ad-b550-8d692ad74d0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9294f7a-2c40-42ad-b550-8d692ad74d0d",
    "outputId": "0fb7e103-ec3e-441b-f0a6-e1868d7be62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The morals of the story could be:\n",
      "1. Sometimes unexpected events or people can be beneficial in unexpected ways.\n",
      "2. True intentions and loyalty are revealed during challenging situations.\n",
      "3. It is important to treat others with kindness and respect, as it may lead to positive outcomes.\n",
      "4. Seeking protection or help from unexpected sources can sometimes lead to positive results.\n",
      "5. Treat others well, as you never know when you may need their help in the future.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"provide me morals of stories?\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17eb2ff-94d7-459e-a853-6336e9584a72",
   "metadata": {
    "id": "b17eb2ff-94d7-459e-a853-6336e9584a72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee1db6-ea3b-476e-84f9-431e621134ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
