{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2d41b06a-28b7-4366-bb5e-86a802320288",
      "metadata": {
        "id": "2d41b06a-28b7-4366-bb5e-86a802320288"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=\" \""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_community"
      ],
      "metadata": {
        "id": "6qEiqLL-v0Fl"
      },
      "id": "6qEiqLL-v0Fl",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_openai"
      ],
      "metadata": {
        "id": "9g2HV3ZmwGj7"
      },
      "id": "9g2HV3ZmwGj7",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "TRDuTtOqxeFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f5358f-5772-479c-be1f-611e85606307"
      },
      "id": "TRDuTtOqxeFn",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n"
      ],
      "metadata": {
        "id": "gZzZJABiy525",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a25f3b4-e388-48d4-fece-478626134f32"
      },
      "id": "gZzZJABiy525",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87659dae-db22-4bbd-9b46-f1c1499462aa",
      "metadata": {
        "id": "87659dae-db22-4bbd-9b46-f1c1499462aa"
      },
      "source": [
        "# Loading the Document into Database(FAISS-Facebook AI similarity search)\n",
        "> For large data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8cb54215-6cc5-4309-af3d-d40e9bcc421d",
      "metadata": {
        "id": "8cb54215-6cc5-4309-af3d-d40e9bcc421d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        DB_FAISS_PATH = \"vectorstore/db_faiss\"\n",
        "        PDF_PATH = \"/content/Ramayanam@RAG.pdf\"\n",
        "\n",
        "        if not os.path.exists(PDF_PATH):\n",
        "            raise FileNotFoundError(f\"PDF file not found: {PDF_PATH}\")\n",
        "\n",
        "        logging.info(\"Loading PDF file...\")\n",
        "        loader = PyPDFLoader(PDF_PATH)\n",
        "        docs = loader.load()\n",
        "\n",
        "        logging.info(\"Splitting text into chunks...\")\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "        splits = text_splitter.split_documents(docs)\n",
        "\n",
        "        logging.info(\"Generating embeddings and storing in FAISS...\")\n",
        "        vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "        vectorstore.save_local(DB_FAISS_PATH)\n",
        "\n",
        "        logging.info(f\"Vectorstore saved at {DB_FAISS_PATH}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "939b508b-5c43-4a12-8303-cb3164c6ea1e",
      "metadata": {
        "id": "939b508b-5c43-4a12-8303-cb3164c6ea1e"
      },
      "outputs": [],
      "source": [
        "def load_llm():\n",
        "        from langchain_openai import ChatOpenAI\n",
        "        llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) #gpt-4o-mini\n",
        "        return llm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "def load_prompt():\n",
        "        prompt = \"\"\" You need to answer the question in the sentence as same as in the  pdf content. .\n",
        "        Given below is the context and question of the user.\n",
        "        context = {context}\n",
        "        question = {question}\n",
        "        if the answer is not in the pdf , answer \"i donot know what the hell you are asking about\"\n",
        "         \"\"\"\n",
        "        prompt = ChatPromptTemplate.from_template(prompt)\n",
        "        return prompt"
      ],
      "metadata": {
        "id": "ywfXYjwBROIC"
      },
      "id": "ywfXYjwBROIC",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Dependencies\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "\n",
        "def load_knowledgeBasee():\n",
        "        embeddings=OpenAIEmbeddings()\n",
        "        DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
        "        db = FAISS.load_local(DB_FAISS_PATH, embeddings,allow_dangerous_deserialization=True)\n",
        "        return db"
      ],
      "metadata": {
        "id": "KPPaLvcrRQwO"
      },
      "id": "KPPaLvcrRQwO",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knowledgeBase=load_knowledgeBasee()\n",
        "llm=load_llm()\n",
        "prompt=load_prompt()"
      ],
      "metadata": {
        "id": "tty1TRuiRfvR"
      },
      "id": "tty1TRuiRfvR",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "fFDB2LN3Rkzv"
      },
      "id": "fFDB2LN3Rkzv",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "query = \"who is seeta?\"\n",
        "if True:\n",
        "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
        "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
        "\n",
        "    #creating the chain for integrating llm,prompt,stroutputparser\n",
        "    retriever = similar_embeddings.as_retriever()\n",
        "    rag_chain = (\n",
        "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "                        | prompt\n",
        "                        | llm\n",
        "                        | StrOutputParser()\n",
        "                    )\n",
        "\n",
        "    response=rag_chain.invoke(query)"
      ],
      "metadata": {
        "id": "iwu-ajRGRn8Y"
      },
      "id": "iwu-ajRGRn8Y",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1eH4yscZRrFb",
        "outputId": "4db1cf34-c236-4ac4-b05a-6f8282f9243c"
      },
      "id": "1eH4yscZRrFb",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sita is the wife of Rama and the central female character in the Ramayana.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79ZRBbwLRyPr"
      },
      "id": "79ZRBbwLRyPr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}